current_model: xlm-roberta-large, timestamp: 1700699214
  0%|          | 0/10 [00:00<?, ?it/s]/users/ob234/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
 10%|█         | 1/10 [00:23<03:29, 23.27s/it] 20%|██        | 2/10 [00:46<03:04, 23.01s/it] 30%|███       | 3/10 [01:08<02:39, 22.74s/it] 40%|████      | 4/10 [01:31<02:17, 22.84s/it] 50%|█████     | 5/10 [01:54<01:53, 22.75s/it] 60%|██████    | 6/10 [02:16<01:30, 22.55s/it] 70%|███████   | 7/10 [02:37<01:06, 22.17s/it] 80%|████████  | 8/10 [02:58<00:43, 21.84s/it] 90%|█████████ | 9/10 [03:20<00:21, 21.66s/it]100%|██████████| 10/10 [03:41<00:00, 21.56s/it]100%|██████████| 10/10 [03:41<00:00, 22.14s/it]
current_model: bert-large-uncased, timestamp: 1700699440
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:17<02:33, 17.02s/it] 20%|██        | 2/10 [00:34<02:19, 17.44s/it] 30%|███       | 3/10 [00:52<02:02, 17.47s/it] 40%|████      | 4/10 [01:09<01:44, 17.38s/it] 50%|█████     | 5/10 [01:26<01:26, 17.32s/it] 60%|██████    | 6/10 [01:44<01:09, 17.32s/it] 70%|███████   | 7/10 [02:01<00:52, 17.36s/it] 80%|████████  | 8/10 [02:18<00:34, 17.32s/it] 90%|█████████ | 9/10 [02:36<00:17, 17.35s/it]100%|██████████| 10/10 [02:53<00:00, 17.43s/it]100%|██████████| 10/10 [02:53<00:00, 17.37s/it]
current_model: roberta-base, timestamp: 1700699618
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.16s/it] 20%|██        | 2/10 [00:20<01:21, 10.13s/it] 30%|███       | 3/10 [00:30<01:10, 10.09s/it] 40%|████      | 4/10 [00:40<01:00, 10.08s/it] 50%|█████     | 5/10 [00:50<00:50, 10.07s/it] 60%|██████    | 6/10 [01:00<00:40, 10.06s/it] 70%|███████   | 7/10 [01:10<00:30, 10.08s/it] 80%|████████  | 8/10 [01:20<00:20, 10.17s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.16s/it]100%|██████████| 10/10 [01:41<00:00, 10.12s/it]100%|██████████| 10/10 [01:41<00:00, 10.11s/it]
current_model: bert-base-uncased, timestamp: 1700699723
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.95s/it] 20%|██        | 2/10 [00:19<01:19,  9.97s/it] 30%|███       | 3/10 [00:29<01:10, 10.00s/it] 40%|████      | 4/10 [00:39<00:59,  9.98s/it] 50%|█████     | 5/10 [00:49<00:49,  9.97s/it] 60%|██████    | 6/10 [00:59<00:39,  9.97s/it] 70%|███████   | 7/10 [01:09<00:29,  9.97s/it] 80%|████████  | 8/10 [01:19<00:19,  9.99s/it] 90%|█████████ | 9/10 [01:29<00:10, 10.00s/it]100%|██████████| 10/10 [01:39<00:00, 10.03s/it]100%|██████████| 10/10 [01:39<00:00, 10.00s/it]
tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 98.8kB/s]
config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]config.json: 100%|██████████| 483/483 [00:00<00:00, 3.18MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.30MB/s]vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.30MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.13MB/s]tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.12MB/s]
model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]model.safetensors:   4%|▍         | 10.5M/268M [00:00<00:19, 13.3MB/s]model.safetensors:   8%|▊         | 21.0M/268M [00:01<00:11, 20.9MB/s]model.safetensors:  12%|█▏        | 31.5M/268M [00:01<00:09, 25.9MB/s]model.safetensors:  16%|█▌        | 41.9M/268M [00:01<00:07, 29.2MB/s]model.safetensors:  20%|█▉        | 52.4M/268M [00:01<00:06, 31.0MB/s]model.safetensors:  23%|██▎       | 62.9M/268M [00:02<00:06, 32.6MB/s]model.safetensors:  27%|██▋       | 73.4M/268M [00:02<00:05, 33.7MB/s]model.safetensors:  31%|███▏      | 83.9M/268M [00:02<00:05, 33.9MB/s]model.safetensors:  35%|███▌      | 94.4M/268M [00:03<00:05, 34.5MB/s]model.safetensors:  39%|███▉      | 105M/268M [00:03<00:04, 34.9MB/s] model.safetensors:  43%|████▎     | 115M/268M [00:03<00:04, 35.2MB/s]model.safetensors:  47%|████▋     | 126M/268M [00:04<00:04, 35.4MB/s]model.safetensors:  51%|█████     | 136M/268M [00:04<00:03, 35.5MB/s]model.safetensors:  55%|█████▍    | 147M/268M [00:04<00:03, 35.7MB/s]model.safetensors:  59%|█████▊    | 157M/268M [00:04<00:03, 35.8MB/s]model.safetensors:  63%|██████▎   | 168M/268M [00:05<00:02, 35.9MB/s]model.safetensors:  67%|██████▋   | 178M/268M [00:05<00:02, 36.0MB/s]model.safetensors:  70%|███████   | 189M/268M [00:05<00:02, 36.0MB/s]model.safetensors:  74%|███████▍  | 199M/268M [00:06<00:01, 36.1MB/s]model.safetensors:  78%|███████▊  | 210M/268M [00:06<00:01, 36.1MB/s]model.safetensors:  82%|████████▏ | 220M/268M [00:06<00:01, 36.1MB/s]model.safetensors:  86%|████████▌ | 231M/268M [00:06<00:01, 36.1MB/s]model.safetensors:  90%|█████████ | 241M/268M [00:07<00:00, 36.0MB/s]model.safetensors:  94%|█████████▍| 252M/268M [00:07<00:00, 36.0MB/s]model.safetensors:  98%|█████████▊| 262M/268M [00:07<00:00, 36.1MB/s]model.safetensors: 100%|██████████| 268M/268M [00:07<00:00, 36.0MB/s]model.safetensors: 100%|██████████| 268M/268M [00:07<00:00, 33.6MB/s]
current_model: distilbert-base-uncased, timestamp: 1700699837
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:06<01:00,  6.73s/it] 20%|██        | 2/10 [00:13<00:53,  6.67s/it] 30%|███       | 3/10 [00:20<00:46,  6.66s/it] 40%|████      | 4/10 [00:26<00:39,  6.65s/it] 50%|█████     | 5/10 [00:33<00:33,  6.67s/it] 60%|██████    | 6/10 [00:39<00:26,  6.66s/it] 70%|███████   | 7/10 [00:46<00:20,  6.68s/it] 80%|████████  | 8/10 [00:53<00:13,  6.68s/it] 90%|█████████ | 9/10 [01:00<00:06,  6.66s/it]100%|██████████| 10/10 [01:06<00:00,  6.65s/it]100%|██████████| 10/10 [01:06<00:00,  6.66s/it]
config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]config.json: 100%|██████████| 684/684 [00:00<00:00, 6.63MB/s]
spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]spiece.model: 100%|██████████| 760k/760k [00:00<00:00, 3.07MB/s]spiece.model: 100%|██████████| 760k/760k [00:00<00:00, 3.06MB/s]
tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 1.31M/1.31M [00:00<00:00, 5.42MB/s]tokenizer.json: 100%|██████████| 1.31M/1.31M [00:00<00:00, 5.39MB/s]
model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]model.safetensors:  22%|██▏       | 10.5M/47.4M [00:00<00:02, 16.5MB/s]model.safetensors:  44%|████▍     | 21.0M/47.4M [00:00<00:01, 24.1MB/s]model.safetensors:  66%|██████▋   | 31.5M/47.4M [00:01<00:00, 28.5MB/s]model.safetensors:  89%|████████▊ | 41.9M/47.4M [00:01<00:00, 31.1MB/s]model.safetensors: 100%|██████████| 47.4M/47.4M [00:01<00:00, 32.0MB/s]model.safetensors: 100%|██████████| 47.4M/47.4M [00:01<00:00, 28.4MB/s]
current_model: albert-base-v2, timestamp: 1700699910
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.52s/it] 20%|██        | 2/10 [00:22<01:29, 11.21s/it] 30%|███       | 3/10 [00:33<01:17, 11.09s/it] 40%|████      | 4/10 [00:44<01:06, 11.08s/it] 50%|█████     | 5/10 [00:55<00:55, 11.02s/it] 60%|██████    | 6/10 [01:06<00:43, 10.97s/it] 70%|███████   | 7/10 [01:17<00:32, 10.94s/it] 80%|████████  | 8/10 [01:28<00:21, 10.93s/it] 90%|█████████ | 9/10 [01:39<00:10, 10.95s/it]100%|██████████| 10/10 [01:50<00:00, 10.99s/it]100%|██████████| 10/10 [01:50<00:00, 11.02s/it]
end experiment :)